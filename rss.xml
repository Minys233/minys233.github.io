<?xml version="1.0" encoding="utf-8"?>






<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Minys&#39;s blog</title>
        <link>https://minys233.github.io/</link>
        <description>siteDescription</description>
        <generator>Hugo 0.61.0 https://gohugo.io/</generator>
        
            <language>en_US</language>
        
        
            <managingEditor>minys@foxmail.com (Minys)</managingEditor>
        
        
            <webMaster>minys@foxmail.com (Minys)</webMaster>
        
        
            <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
        
        <lastBuildDate>Fri, 22 May 2020 01:02:43 &#43;0800</lastBuildDate>
        
            <atom:link rel="self" type="application/rss&#43;xml" href="https://minys233.github.io/rss.xml" />
        
        
            <item>
                <title>How Powerful Are Graph Neural Networks?</title>
                <link>https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/</link>
                <guid isPermaLink="true">https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/</guid>
                <pubDate>Wed, 20 May 2020 20:59:03 &#43;0800</pubDate>
                
                    <author>minys@foxmail.com (Minys)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;preliminary&#34;&gt;Preliminary&lt;/h2&gt;
&lt;h3 id=&#34;the-weisfeiler-lehman-isomorphism-test&#34;&gt;The Weisfeiler-Lehman Isomorphism Test&lt;/h3&gt;
&lt;p&gt;For a easy-to understand explanation, please refer to &lt;a href=&#34;https://davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/&#34;&gt;this link&lt;/a&gt;. Here, I simply summarize it briefly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-112619.png&#34; alt=&#34;Two isomorphic graphs&#34;&gt;
&lt;em&gt;Graph 1 and Graph 2 are isomorphic. The correspondance between nodes is illustrated by the node colors and numbers.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In general, determining whether two graphs are isomorphic when the correspondance is not provided is a challenging problem; precisely how hard this problem is remains an open question in computer science. It isn&#39;t known whether there is a polynomial time algorithm for determining whether graphs are isomorphic, and it also isn&#39;t known whether the problem is NP-complete. The graph isomorphism problem may even be an example of an &lt;a href=&#34;https://en.wikipedia.org/wiki/NP-intermediate&#34;&gt;NP-intermediate&lt;/a&gt; problem, but this would only be possible if $P\ne NP$.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;From link above&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Weisfeiler-Lehman Isomorphism Test produces canonical forms of graphs. &lt;strong&gt;If the canonical forms of two graphs are not same, then two graphs are not isomorphic&lt;/strong&gt;. It is possible for two graphs to have same canonical forms but are not isomorphic. The algorithm iterative encode nodes (usually by a hash function) in a graph based on its neighbors to generate some kind of &amp;ldquo;fingerprint&amp;rdquo; or &amp;ldquo;signature&amp;rdquo;. With same initialization, we could find correspondance nodes in two graphs when they share the same fingerprint.&lt;/p&gt;
&lt;h3 id=&#34;graph-neural-network&#34;&gt;Graph neural network&lt;/h3&gt;
&lt;p&gt;最为常见的GNN范式可以如此描述.对于图 $G=(V,E)$ , $X_v$ 表示其节点 $v\in V$ 的特征向量(feature vector)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. 图网络的流程可以简单概括如下：
$$
\begin{aligned}
a_v^{(k)}&amp;amp;=\text{AGGREGATE}^{(k)}\left( \left{\left. h_u^{(k-1)}\right|u\in \mathcal{N}(v) \right} \right), \\&lt;br&gt;
h_v^{(k)} &amp;amp;= \text{COMGINE}^{(k)}\left( h_v^{(k-1)}, a_v^{(k)} \right),\\&lt;br&gt;
h_G &amp;amp;= \text{READOUT}\left( \left{ \left. h_v^{(K)} \right| v\in G \right} \right)
\end{aligned}
$$
其中, $h_v^{(k)}$ 表示节点 $v$ 在第 $k$ 层/循环时的特征向量; $h_v^{(k)}$ 的初始值为 $X_v$ ; $\mathcal{N}(v)$ 表示节点 $v$ 的邻居节点. 其中三个大写字母表示的函数是区别于不同GNN之间的重要因素. 大概汇总如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GraphSAGE (Hamilton et al., 2017a)
&lt;ul&gt;
&lt;li&gt;$a_v^{(k)}=\text{MAX}\left( \left{\left. \text{ReLU}\left(W\cdot h_u^{(k-1)}\right)  \right|u\in \mathcal{N}(v) \right} \right)$&lt;/li&gt;
&lt;li&gt;$h_v^{(k)} = W\cdot \left[ h_V^{(k-1)}, a_v^{(k)} \right]$&lt;/li&gt;
&lt;li&gt;$\text{MAX}$ 表示MaxPooling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GCN (Kipf &amp;amp; Welling, 2017)
&lt;ul&gt;
&lt;li&gt;$h_v^{(k)}=\text{ReLU}\left(W\cdot \text{MEAN}\left{ h_u^{(k-1)}, \forall u\in \mathcal{N}(v)\cup {v}  \right}\right)$&lt;/li&gt;
&lt;li&gt;两个函数合二为一&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常见的图上任务有两类：① 节点分类, 每个节点 $v$ 都有一个对应标签 $y_v$, GNN学到了节点表示 $h_v$ 后, 通过映射函数进行预测, 使得 $y_v=f(h_v)$ ; ②图分类, 对于每一个图 $G$, 都有一个标签 $y_G$ , 通过GNN学到图的表示 $h_G$ 后, 通过映射函数进行预测, 使得 $y_G=f(h_G)$.&lt;/p&gt;
&lt;h2 id=&#34;heading&#34;&gt;工作简述&lt;/h2&gt;
&lt;p&gt;文章通过理论论证+实验验证的方法指出了做出了两个主要贡献:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;论证并给出了各种GNN变体的表达能力的上限和达到的条件&lt;/li&gt;
&lt;li&gt;通过理论分析设计出了理论上更具优的网络结构GIN&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;理论证明&lt;/h2&gt;
&lt;p&gt;这里阐述一个大概的思路. 为了论证GNN的表示能力, 考察何种条件下GNN能将两个节点映射到嵌入空间中相同的位置. 理想情况下, 最具表达能力的GNN将两个节点映射到嵌入空间中相同的位置&lt;strong&gt;当且仅当&lt;/strong&gt;两个节点具有相同的子树结构 (aggregate N 次形成的树). 这表示GNN的 $\text{AGGREGATE}$ 函数必须是单射的. 而GNN这种区分能力的上限则是WL test. 作者证明,只有当$\text{AGGREGATE}$ , $\text{COMBINE}$ 以及 $\text{READOUT}$ 都是单射的时候, GNN将在描述节点的特征上达到WL test的性能.&lt;/p&gt;
&lt;p&gt;注: 文中这里提出了很多引理, 针对如何设计一个单射的multiset function. 这些是GIN设计及有效的证据.&lt;/p&gt;
&lt;h2 id=&#34;graph-isomorphism-network-gin&#34;&gt;Graph Isomorphism Network (GIN)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-155525.png&#34; alt=&#34;一些引理最终得到的命题&#34;&gt;&lt;/p&gt;
&lt;p&gt;这一命题构造了一系列符合要求的单设函数. 如果使用MLP学习其中的映射, 那么就得到了GIN的节点表示更新函数就可以写作为下式. 其中MLP可对前一次和下一次的 $\phi f$ 函数同时建模. 至此, 作者表明他们设计出了一个理论上达到表示能力上界的图神经网络.
$$
h_v^{(k)}=\text{MLP}^{(k)}\left(\left( 1+\epsilon^{(k)} \right)\cdot h_v^{(k-1)}+\sum_{u\in\mathcal{N}(v)}h_u^{(k-1)}\right)
$$
最后, 还差一个 $\text{READOUT}$ 函数. 作者提出, 在节点对应的遍历树逐渐趋近整个图的时候, 图中的特征将会有更好的判别性能. 但迭代轮数较小时候的特征却可以拥有更好的泛化性能&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. 因此作者表示为了能考虑到图中所有结构信息, 我们应当使用所有迭代过程中的特征. 作者通过一个与 Jumping Knowledge Network类似的架构实现了这样的操作:
$$
h_G=\text{CONCAT} \left( \text{READOUT}\left.\left.\left(\left{h_v^{(k)}\right|v \in G\right} \right) \right| k=0,1,\dots,K \right)
$$
根据上面的命题, 如果令 $\text{READOUT}$ 为求和函数, 那么它也将符合单射的条件. 作者在4个生信数据集+5个社交网络数据集上进行了测试, 结果自然是几乎全部怒砍第一.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-163130.png&#34; alt=&#34;GIN不同数据集上的测评结果&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;gnn&#34;&gt;关于其他的GNN&lt;/h2&gt;
&lt;p&gt;其他的GNN虽然没有GIN这么强大,但是同样会捕捉一些图上有趣的性质. 作者针对GCN和GraphSAGE中不满足单设条件的①1层感知器, ②均值或max-pooling而非求和的 $\text{AGGREGATE}$ 函数做了消融实验. 它们都在一些图结构上无法分辨.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-164916.png&#34; alt=&#34;表达能力排序&#34;&gt;
&lt;em&gt;不同的 $\text{AGGREGATE}$ 函数的表示能力排序. Input表示将要输入的一堆目标节点的邻居; 右边排序说明了SUM捕捉到multiset中所有元素的特征; MEAN捕捉到了节点大致的分布; MAX忽视了multiset, 将其退化为简单地集合 (SET). 不同颜色的节点代表不同的特征值.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;1&#34;&gt;1层感知器&lt;/h3&gt;
&lt;p&gt;文章证明了1层感知器 (线性组合+激活函数) 并不能对某些网络结构进行分辨. 即文中引理7:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lemma 7.&lt;/strong&gt; &lt;em&gt;There exist finite multisets&lt;/em&gt; $X_1 \ne X_2$ &lt;em&gt;so that for any linear mapping&lt;/em&gt; $W$, $\sum_{􏰄x\in X_1} \text{ReLU}(Wx)=\sum_{􏰄x\in X_2} \text{ReLU}(Wx)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;证明过程主要思路是, 1层感知器和线性映射区别很小, GNN会退化到每一层仅仅将邻居节点求和. 另外, 众所周知, 1层感知器并不能对任意的函数进行近似.&lt;/p&gt;
&lt;h3 id=&#34;meanmax-pooling&#34;&gt;Mean和Max-pooling&lt;/h3&gt;
&lt;p&gt;这两个函数虽然都是组合不变的, 但是他们并非单射的. 根据之前的证明, 他们并不能区分某些图结构. 对于Mean函数,很容易能看出来, 它刻画的是周围邻居的均值, 或者可以理解为分布情况. 而对Max-pooling, 它则将原本是Multiset的邻居特征集合退化为一个简单集合, 并使用唯一元素代表所有邻居. 这些结论都有形式化证明, 这里不再赘述.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-165229.png&#34; alt=&#34;&#34;&gt;
&lt;em&gt;使得不同 $\text{AGGREGATE}$ 函数输出相同的图结构. 其中不同颜色代表不同的特征值. 简单计算就可以看出原因.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;heading-2&#34;&gt;结果与总结&lt;/h2&gt;
&lt;p&gt;这篇论文亮点就在通过WL test分析并设计的GNN确实在下游任务中比原来几种GNN好得多. 这篇文章代码也出奇简单. 有空一定要好好看看, 留个坑.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这里特征向量指的并非线性代数中的特征向量. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;作者没有解释, 我也不是很理解这里 &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/graph-neural-network-gnn/">Graph Neural Network (GNN)</category>
                                
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>学术英语写作</title>
                <link>https://minys233.github.io/posts/%E5%AD%A6%E6%9C%AF%E8%8B%B1%E8%AF%AD%E5%86%99%E4%BD%9C/</link>
                <guid isPermaLink="true">https://minys233.github.io/posts/%E5%AD%A6%E6%9C%AF%E8%8B%B1%E8%AF%AD%E5%86%99%E4%BD%9C/</guid>
                <pubDate>Wed, 20 May 2020 15:30:54 &#43;0800</pubDate>
                
                    <author>minys@foxmail.com (Minys)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;blockquote&gt;
&lt;p&gt;The process is &lt;strong&gt;seeded with&lt;/strong&gt; $N$ vectors &amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;Constrained Graph Variational Autoencoders for Molecule Design&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GNNs &lt;strong&gt;follow&lt;/strong&gt; a neighborhood aggregation &lt;strong&gt;scheme&lt;/strong&gt;, where the representation vector of a node is computed by recursively aggregating and trans- forming representation vectors of its neighboring nodes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Recently, there has been &lt;strong&gt;a surge of interest in&lt;/strong&gt; Graph Neural Network (GNN) approaches for representation learning of graphs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;How Powerful Are Graph Neural Networks?&lt;/em&gt;&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/academic-writing/">Academic Writing</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Strategies for Pre Training Graph Neural Networks</title>
                <link>https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/</link>
                <guid isPermaLink="true">https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/</guid>
                <pubDate>Wed, 20 May 2020 15:26:23 &#43;0800</pubDate>
                
                    <author>minys@foxmail.com (Minys)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;heading&#34;&gt;问题提出&lt;/h2&gt;
&lt;p&gt;文章首先提出迁移学习在CV与NLP中已经应用广泛了，但在图数据上相应的预训练的工作还比较少。预训练主要解决目前图数据集的两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;task-specific labeled data can be extremely scarce.&lt;/li&gt;
&lt;li&gt;Graph data from real-world often contain out-of-distribution samples.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第一个问题很好理解，在化学生物领域中，图数据（eg: molecule, protein, etc.）对应的标签的获取过程需要做实验，是资源密集且时间密集的。第二个问题个人理解指的是数据的整体分布和条件分布的区别。例如，所有已发现的分子数据库可看作是整体分布。而对特定的任务如MoleculeNet中的BBBP数据集&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，数据的分子则是在某些隐含条件下的，如具有一定的水溶性和脂溶性、常温下不太可能是气体、不太可能含有特定有毒的重金属元素/官能团。&lt;/p&gt;
&lt;p&gt;因此，不少研究都发现，简单地增加有标数据的量并不能一定让预训练或迁移学习进行得更好。相反，预训练需要领域知识来合理地选择和特定下游任务有关的数据。相反，如果下游任务和预训练的任务差别太大，则有可能导致“负迁移”（negative transfer）的问题。&lt;/p&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;解决方案&lt;/h2&gt;
&lt;h3 id=&#34;heading-2&#34;&gt;简述&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-170447%402x.png&#34; alt=&#34;思路简述&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图，本文提出使用节点水平+图水平的预训练使得图网络既能学到节点与边层面上的特征（局部特征），也能捕捉到图级别的特征（全局特征）。作者为预训练设计了特定的任务，如上图右边，以此来对特定的图中信息进行建模。本文通过对比使用了比较新GIN模型作为预训练的图网络。&lt;/p&gt;
&lt;h3 id=&#34;heading-3&#34;&gt;节点的预训练&lt;/h3&gt;
&lt;p&gt;承上，节点的预训练作者提出了两种方案，分别针对邻居结构信息和自身节点信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-170517%402x.png&#34; alt=&#34;节点嵌入&#34;&gt;&lt;/p&gt;
&lt;p&gt;**Context prediction.**对每一个节点 $v$ ， $K$-hop 邻居指该节点出发最多 $K$-hop 以内的所有节点和边。也即是一个常见的 $K$ 层GNN能够搜集信息的范围，对应节点的表示向量 $h_v^{(K)}$ 则取决于它的 $K$-hop 邻居。Context graph 表示一些节点 $v$ 的邻居结构。它由两个参数 $r_1, r_2$ 控制。对于节点 $v$，表示由所有与 $v$ 距离 $r_1$-hop 和 $r_2$-hop 之间的节点和边所构成的子图，可近似看做一个环形区域。令 $r_1 &amp;lt; K$，并将 $K$-hop 邻居和Context graph的交集被称为Context anchor nodes。这一任务如上图(a)所示，第一步先使用一个辅助GNN&#39;来得到Context graph中的节点向量表示，并对Context anchor nodes的表示求平均，得到绿色的向量，对于图 $G$ 中的节点 $v$ ，这样得到的向量为 $c_v^G$。第二步，用主GNN在 $K$-hop 邻居组成的子图上得到 $v$ 的表示 $h_v^{(K)}$。预训练的目标即为：
$$
\sigma(h_v^{(K)}\cdot c_{v&amp;rsquo;}^G) \approx 1 \;\;\text{if $v$ and $v&#39;$ are same node}
$$
$\sigma(\cdot)$ 表示$\text{Sigmoid}$函数。第三部，在训练中使用negative sampling，控制 $v&#39;=v$ 或 $G&#39;=G$，让正负样本比例为1。这实际上是要学到图的拓扑结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Attribute masking.&lt;/strong&gt; 随机mask掉分子图中的一些节点和边的属性，使用GNN预测。这个任务原理没有这么复杂，不再赘述。&lt;/p&gt;
&lt;h3 id=&#34;heading-4&#34;&gt;图的预训练&lt;/h3&gt;
&lt;p&gt;图 $G$ 的向量表示 $h_G$ 下游任务进行微调训练时候直接使用的特征，我们应当让这类特征包含相关的领域知识。作者提出，使用图级别多任务有监督预训练（graph-level multi-task supervised pre-training）来同时预测同一个图的多个标签。但是，如果只是单纯的这样训练，如果预训练的任务与下游任务相关性不强或，则可能出现负迁移的现象。因此，作者认为图的预训练仅仅提供了图层面上的监督，即使节点表示学的很好，但图表示很可能在预训练阶段由于各种原因是没那么有意义的。因此，作者表示要缓解这个问题，就要先进行节点预训练，再进行图的预训练&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;。另外，作者还说可以用图网络预测图之间的相似性来进行图的预训练。然而他说这个复杂度太高，他不做。&lt;/p&gt;
&lt;h2 id=&#34;heading-5&#34;&gt;实验和结果&lt;/h2&gt;
&lt;p&gt;实验分别在化学任务和生物学任务上进行预训练效果测试。预训练数据来源是ZINC15，只在其中选了2百万个分子&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;。详细数据和方法略去，仅介绍结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-183500%402x.png&#34; alt=&#34;所有下游任务和与训练策略的比较&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是GIN使用不同的与训练策略在下游任务（化学）中的表现，测评指标是ROC-AUC（%）。加粗字体表示最好的几个（best and comparable），灰框的表示出现了负迁移，结果比不预训练的网络还差。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-183515%402x.png&#34; alt=&#34;不同模型是否预训练的结果变化&#34;&gt;&lt;/p&gt;
&lt;p&gt;不同图网络模型在化学和生物两大类下游任务中的表现，比较预训练与否所带来的ROC-AUC（%）的变化，可以轻松看出GIN是最适合预训练的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-184420%402x.png&#34; alt=&#34;使用GIN与不同与训练策略进行蛋白质功能预测&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-184432%402x.png&#34; alt=&#34;不同与训练策略的训练集和验证集ROC-AUC变化情况&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;印证了越复杂的模型就越能更好地利用预训练，相反，越有限的模型就越不能受益于预训练。&lt;/li&gt;
&lt;li&gt;仅仅进行了图级别的预训练是不够的，将导致较多负迁移现象（2/8）。&lt;/li&gt;
&lt;li&gt;仅仅进行了节点级别的预训练也是不够的，也会导致负迁移现象（1/8）。&lt;/li&gt;
&lt;li&gt;结合节点级别和图级别的预训练将能达到最优的下游任务表现，同时消除了负迁移。&lt;/li&gt;
&lt;li&gt;作者声称他的方法做到了目前最好&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;
&lt;li&gt;与训练模型在下游任务训练时能更快收敛（显然）。&lt;/li&gt;
&lt;/ol&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这个数据集是测量一些化合物是否能突破人体血脑屏障的。 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这不是废话吗😓，反过来的话节点的预训练不就没用了。感觉这里把问题没讲清楚，实际上文中似乎就是把能获取到的数据都拿来预训练。 &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;我个人也发现无标签分子的预训练一两百万就差不多很足够了，再多就没有意义了。 &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;存疑，这几个数据集合同样是scaffold划分，都没有达到MoleculeNet的给出的结果，不知是如何state-of-the-art的。 &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/graph-neural-network-gnn/">Graph Neural Network (GNN)</category>
                                
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>功能测试</title>
                <link>https://minys233.github.io/posts/test-my-site/</link>
                <guid isPermaLink="true">https://minys233.github.io/posts/test-my-site/</guid>
                <pubDate>Tue, 19 May 2020 18:49:55 &#43;0000</pubDate>
                
                    <author>minys@foxmail.com (Minys)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h1 id=&#34;heading&#34;&gt;这是一个一级标题&lt;/h1&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;这是一个二级标题&lt;/h2&gt;
&lt;h1 id=&#34;heading-2&#34;&gt;数学公式&lt;/h1&gt;
&lt;p&gt;简单公式$A+B=C$这是行内公式
$$ a^2 + b^2 = c^2$$&lt;/p&gt;
&lt;p&gt;$$x=\frac{-b\pm\sqrt{4ac}}{2a}$$
复杂公式
$$
\begin{aligned}
\mathcal{L} ( \mu ,\sigma^2 ) &amp;amp;= \prod_{i = 1}^n \left\lbrace  \frac{1}{\sqrt{2 \pi} \sigma } \text{exp} \left\lbrace - \frac{( x_i - \mu)^2}{2 \sigma^2}\right\rbrace \right\rbrace ,\\&lt;br&gt;
&amp;amp;= (2 \pi \sigma^2)^{- \frac{n}{2}} \text{exp} \left\lbrace - \frac{1}{2 \sigma^2} \sum_{i = 1}^{n} (x_i - \mu)^2 \right\rbrace .
\end{aligned}
$$&lt;/p&gt;
&lt;h1 id=&#34;toc&#34;&gt;公式作为TOC项目&lt;/h1&gt;
&lt;h2 id=&#34;xfrac-bpmsqrt4ac2a&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h2&gt;
&lt;h3 id=&#34;xfrac-bpmsqrt4ac2a-1&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h3&gt;
&lt;h4 id=&#34;xfrac-bpmsqrt4ac2a-2&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h4&gt;
&lt;h5 id=&#34;xfrac-bpmsqrt4ac2a-3&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h5&gt;
&lt;p&gt;一元二次方程解的公式$x= \frac{-b\pm\sqrt{4ac}}{2a}$&lt;/p&gt;
&lt;h1 id=&#34;ceh3o&#34;&gt;化学式$\ce{H3O+}$&lt;/h1&gt;
&lt;p&gt;$\ce{[AgCl2]-}$&lt;/p&gt;
&lt;p&gt;$\ce{NaOH(aq,$\infty$)}$&lt;/p&gt;
&lt;p&gt;$\ce{Hg^2+ -&amp;gt;[I-]  $\underset{\mathrm{red}}{\ce{HgI2}}$  -&amp;gt;[I-]  $\underset{\mathrm{red}}{\ce{[Hg^{II}I4]^2-}}$}$&lt;/p&gt;
&lt;h1 id=&#34;emoji&#34;&gt;Emoji&lt;/h1&gt;
&lt;p&gt;🌶💉🔟🐮🍺&lt;/p&gt;
&lt;h1 id=&#34;heading-3&#34;&gt;代码块&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bar&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
      &lt;span class=&#34;k&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;this is {self.foo}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/categories/%E9%9A%8F%E4%BE%BF%E5%86%99%E5%86%99/">随便写写</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://minys233.github.io/tags/%E6%B5%8B%E8%AF%95/">测试</category>
                                
                            
                        
                    
                
            </item>
        
    </channel>
</rss>
