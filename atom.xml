<?xml version="1.0" encoding="utf-8"?>


<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title type="text">Minys&#39;s blog</title>
    <subtitle type="html">Minys&#39;s blog - Record my ordinary life</subtitle>
    <updated>2020-06-22T22:30:06&#43;08:00</updated>
    <id>https://minys233.github.io/</id>
    <link rel="alternate" type="text/html" href="https://minys233.github.io/" />
    <link rel="self" type="application/atom&#43;xml" href="https://minys233.github.io/atom.xml" />
    <author>
            <name>Minys</name>
            <uri>https://minys233.github.io/</uri>
            
                <email>minys@foxmail.com</email>
            </author>
    <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights>
    <generator uri="https://gohugo.io/" version="0.72.0-DEV">Hugo</generator>
        <entry>
            <title type="text">机器学习轶事趣闻</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BD%B6%E4%BA%8B%E8%B6%A3%E9%97%BB/" />
            <id>https://minys233.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BD%B6%E4%BA%8B%E8%B6%A3%E9%97%BB/</id>
            <updated>2020-06-03T12:33:15&#43;08:00</updated>
            <published>2020-06-01T21:18:25&#43;08:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">记录一些有意思且有意义的机器学习领域的奇闻异事, 或许能为我平白无奇的研究找些乐子.</summary>
            
                <content type="html">&lt;h2 id=&#34;the-gelato-bet&#34;&gt;The Gelato Bet&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;本节翻译自&lt;a href=&#34;https://people.eecs.berkeley.edu/~efros/gelato_bet.html&#34;&gt;The Gelato Bet&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;打赌在过去的日子中是科学圈中的趣事. 在牛津剑桥 (oxbridge) 大学的高级公共休息室(SCR)中, 我们仍然可以找到&lt;a href=&#34;https://exetercollegespecialcollections.com/tag/betting-books/&#34;&gt;旧赌本&lt;/a&gt;, 上面记录着牛津剑桥教员们打赌的历史, 读起来非常有趣. 在伯克利, 我们试着坚持这样的传统, 只是不是在烟雾缭绕的休息室, 而是在Nefli咖啡馆 (令人难过的是, 现已不在存在). 接下来打得这个赌发生在2014年9月23日, 三位公证人 (&lt;a href=&#34;https://www.cs.cmu.edu/~katef/&#34;&gt;Kateria Fragkiadaki&lt;/a&gt;, &lt;a href=&#34;http://www.philkr.net/&#34;&gt;Philipp Krähenbühl&lt;/a&gt;, and &lt;a href=&#34;https://gkioxari.github.io/&#34;&gt;Georgia Gkioxari&lt;/a&gt;, 照片见原链接) 面对面手握手打的赌.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;If, by the first day of autumn (Sept 23) of 2015, a method will exist that can match or beat the performance of R-CNN on Pascal VOC detection, without the use of any extra, human annotations (e.g. ImageNet) as pre-training, Mr. Malik promises to buy Mr. Efros one (1) gelato (2 scoops: one chocolate, one vanilla).&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;如果, 在2015年秋天的第一天前 (2015年9月23日), 在不适用任何额外的, 人工标注数据 (如 ImageNet) 的预训练下, 出现一种方法能够在Pascal VOC检测任务性能上追平或击败R-CNN的话, Malik先生允诺为Efros先生买一个 glato (一种意大利冰淇淋), 冰淇淋有两个球, 一个巧克力味, 一个香草味. &amp;ldquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;打这个赌的背景故事如下. R-CNN在CVPR 2014上被提出, 并在PASCAL VOC检测任务上拥有令人印象深刻的性能. 我认为这是计算机视觉社区中比较怀疑深度学习的成员 (包括我自己) 最终拥抱深度学习的关键时刻. 然而, 这其中还有一个难题: 据称, PASCAL VOC数据量太小, 无法从头训练出一个卷积网络, 因此, 网络不得不现在ImageNet上预训练, 然后在PASCAL上微调 (fine-tune). 这对我来说很是奇怪: PASCAL和ImageNet数据集是差异很大的数据集, 其中的标签集和重点完全不同&amp;hellip; 为什么在已个数据集上训练会有利于另一个数据集上的性能呢? 那天下午在Nefli喝咖啡的时候, 我提出或许网络并不需要ImageNet的标签, 而仅仅需要图像用以预训练. 说穿了, 我想要回答的科学问题是: 学习好的表示需要语义监督吗? (does one need semantic supervision to learn a good representation?) 于是, Gelato Bet诞生了. 为了吸引其他的研究者参与这个赌局中来, 我承诺将分享我的glato冰淇淋给那些帮助我赢得这场赌局的研究团队.&lt;/p&gt;
&lt;p&gt;显而易见, 我输了, 即使是5年过去了, 我们依然没能够超越ImageNet预训练后的模型在PASCAL VOC任务上的性能 (虽然有几种方法距离超越仅一步之遥). 事实上, PASCAL任务需要预训练这个假定很可能一开始就是&lt;a href=&#34;https://arxiv.org/abs/1708.01241&#34;&gt;有问题的&lt;/a&gt;. 另一方面, 这个赌局对我们现在称之为的&amp;quot;自监督学习&amp;quot;在ICCV&#39;15上的提出可能起了一定作用. 最后, 这件事给我上了宝贵的一课: 和自己导师打赌前一定要三思而后行!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~efros/&#34;&gt;Alyosha Efros&lt;/a&gt;
Berkeley, CA
2019年3月&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://people.eecs.berkeley.edu/~efros/img/malik_gelato.jpg&#34; alt=&#34;胜利者在享用glato冰淇淋&#34; title=&#34;Efros在享用他的双球冰淇淋&#34;&gt;&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E6%9D%82%E8%AE%B0/" term="杂记" label="杂记" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/machine-learning/" term="Machine Learning" label="Machine Learning" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">Learning Multimodal Graph to Graph Translation for Molecular Optimization</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/" />
            <id>https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/</id>
            <updated>2020-06-03T03:12:54&#43;08:00</updated>
            <published>2020-05-28T22:52:13&#43;08:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">读后总结, 刊于ICLR 2019</summary>
            
                <content type="html">&lt;h2 id=&#34;论文简述&#34;&gt;论文简述&lt;/h2&gt;
&lt;p&gt;药物发现的目标是设计具有特定期望的化学性质的分子.  这个任务很具有挑战性, 因为化学空间是巨大的且难于探索. 一个解决该问题的流行的方法使匹配分子对分析 (MMPA). 通过学习&amp;quot;分子释义&amp;rdquo;, 来提升化合物特定的性质. 这与机器翻译的策略很相似: MMPA输入一个分子对 $\{(X, Y)\}$, 其中 $Y$ 看做是 $X$ 的释义/含义, 并具有更好的化学性质. 然而现有的MMPA方法将分子对提炼为图转化 (graph transformation) 问题, 而非更普适的图之间的翻译问题.&lt;/p&gt;
&lt;p&gt;因此,本文提出将分子优化问题 (molecular optimization) 看做一个图对图的翻译 (graph-to-graph translation). 给定分子对的文集, 任务目标是学习如何将输入的分子图翻译为更好的图. 这个思路中涉及很多问题: 如何编码图, 如何生成图. 其中如何编码图已有若干工作, 但在不诉诸于专业领域知识的情况下生成图, 确是一个难题. 另外, 一个分子的&amp;quot;释义&amp;quot;可以是多个, 因为有不同的分子优化策略. 因此, 本文的问题最终转化为如何生成多模态的分子图.&lt;/p&gt;
&lt;p&gt;本文使用了junction tree encoder-decoder来在注意力机制下解码生成分子图. 为了 (a) 捕捉不同的输出, 本文在解码过程中引入了隐码 (latent code), 使其能捕捉有意义的分子变种; 为了 (b) 避免无效的翻译结果, 本文以入了对抗训练, 使用随机选择的隐码对齐模型生成的图的分布和以观察到的有效输出 (真值) 的分布.&lt;/p&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;h3 id=&#34;junction-tree-encoder-decoder&#34;&gt;Junction Tree Encoder-Decoder&lt;/h3&gt;
&lt;p&gt;本文的翻译模型拓展了junction tree variational autoencoder. 我们将每个分子看做从子图 (原子团/官能团) 构建而来, 基于一个合法的分子子结构库. Junction tree中的原子团代表着分子的骨架 (scaffold), 如下图所示. 分子解码的过程包括: 生成junction tree; 合并树中节点得到分子. 这样从粗到细的过程将允许我们很轻松的控制生成的图在化学上是正确的的, 并且能将分子在不同层级取得较为丰富的表示.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-06-01-145411.png&#34; alt=&#34;&#34; title=&#34;Encoder-decoder示意图. 分子表示为对应的图结构和记录分子骨架的junction tree. 其中树中的节点表示一个子结构. 解码过程中, 模型先解码出junction tree, 而后联合子结构最终预测出分子图.&#34;&gt;&lt;/p&gt;
&lt;p&gt;模型的编码器包含: 一个图消息传递网络, 编码树和图至嵌入向量. 模型的解码器包含: (1) 树结构解码器, 用以预测junction tree的结构, (2) 一个图解码器, 用以将树扩充为分子图.&lt;/p&gt;
&lt;h3 id=&#34;树图二合一编码器&#34;&gt;树图二合一编码器&lt;/h3&gt;
&lt;p&gt;图定义为 $G=(\mathcal{V}, \mathcal{E})$. 图中节点 $v$ 具有特征 $\boldsymbol f_v$ . 对原子来说, 其中包含了原子类型, 化合价等原子性质. 对junction tree中的节点 (文中称cluster),  $\boldsymbol f_v$ 是one-hot向量, 表示其类别. 类似地, 边 $(u,v)\in\mathcal{E}$ 也有对应的特征 $\boldsymbol f_{uv}$. $N(v)$ 表示节点 $v$ 邻居构成的集合. 每条边 $(u,v)$ 有两个隐向量: $\boldsymbol\nu_{uv} , \boldsymbol\nu_{vu}$ , 分别表示两个方向传递的消息. 则消息传递网络通过神经网络 $g_1(\cdot)$ 更新图中边上的消息:&lt;/p&gt;
&lt;p&gt;$$
\boldsymbol\nu_{uv}^{(t)}=g_1\left(\boldsymbol f_u,
\boldsymbol f_{uv}, \sum_{w\in N(u)\backslash v}
\boldsymbol\nu_{wu}^{(t-1)}\right)
$$&lt;/p&gt;
&lt;p&gt;其中 $\boldsymbol \nu_{uv}^{(t)}$ 表示第 $t$ 次迭代时边 $(u,v)$ 上的消息, 其初始化为零向量. 图上节点更新顺序是异步的, 即没有预定义的顺序. 在 $T$ 次迭代之后, 我们将图中消息通过神经网络 $g_2(\cdot)$ 聚合, 得到每一个节点的嵌入向量, 其刻画了..图或树中的局部结构..
$$
\boldsymbol x_u = g_2\left( \boldsymbol f_u, \sum_{v\in N(u)} \boldsymbol \nu_{vu}^{(T)} \right)
$$&lt;/p&gt;
&lt;p&gt;对junction tree $\mathcal{T}$ 和分子图 $G$ 都使用消息传递网络编码,得到了 $\{\boldsymbol x_1^{\mathcal{T}},\cdots, \boldsymbol x_n^{\mathcal{T}}\}$ 与 $\{\boldsymbol x_1^{\mathcal{G}},\cdots, \boldsymbol x_n^{\mathcal{G}}\}$ .&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;junction-tree解码器&#34;&gt;Junction Tree解码器&lt;/h3&gt;
&lt;p&gt;这一步的目标是根据编码器输出的树表示和图表示重建junction tree. 这里使用了树循环神经(tree RNN)网络+注意力机制. 构建树的过程是自顶向下的, 每次拓展树的一个节点. 形式化地说, 令 $\tilde{\mathcal E}={(i_1,j_1),\cdots,(i_m,j_m)}$ 为树 $\mathcal{T}$ 的深度优先遍历, 其中 $m=2|\mathcal E|$ 因为每个边从两个方向看要算两次. 令 $\mathcal{\tilde E_t}$ 为 $\mathcal{\tilde E}$ 中前 $t$ 个边. 在第 $t$ 步的解码中, 模型访问节点 $i_t$ 并接受其邻居的消息 $\boldsymbol h_{ij}$ . 消息向量 $\boldsymbol h_{i_t,j_t}$ 通过 树GRU更新:
$$
\boldsymbol h_{i_t,j_t} = \text{GRU}(\boldsymbol f_{i_t}, \{\boldsymbol h_{k, i_t}\}_{(k, i_t)\in \tilde{\mathcal{E}}, k\ne j_t})
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;..拓扑结构预测..&lt;/strong&gt;. 当模型访问节点 $i_t$ 时, 首先通过一层神经网络编码节点特征 $\boldsymbol f_{i_t}$ 和输入消息 $\{\boldsymbol h_{k, i_t}\}$ 来计算计算隐状态 $\boldsymbol h_t$. 模型随后进行二分类, 预测是否拓展这个新节点, 或是回溯回 $i_t$ 的父亲节点. 概率是通过聚合编码器所编码的两组嵌入向量 $\{\boldsymbol x_*^{\mathcal{T}}\}, \{\boldsymbol x_*^{\mathcal{G}}\}$ 而来的.
$$
\begin{aligned}
\boldsymbol h_t &amp;amp;= \tau(\boldsymbol W_1^d\boldsymbol f_{i_t}+\boldsymbol W_2^d\sum_{(k,i_t)\in \tilde{\mathcal{E}}_t}\boldsymbol h_{k,i_t}) \\&lt;br&gt;
\boldsymbol c_t^d &amp;amp;= \text{attention}(\boldsymbol h_t, {\boldsymbol x_*^{\mathcal{T}}}, {\boldsymbol x_*^{\mathcal{G}}}; \boldsymbol U_{att}^d) \\&lt;br&gt;
\boldsymbol p_t &amp;amp;= \sigma(\boldsymbol u^d\cdot\tau(\boldsymbol W_3^d\boldsymbol h_t+\boldsymbol W_4^d\boldsymbol c_t^d))
\end{aligned}
$$
其中 $(\cdot;\boldsymbol U_{att}^d)$ 表示参数为 $\boldsymbol U_{att}^d$ 的注意力机制, 其在树和图上分别计算得到两组注意力分数 ${\boldsymbol \alpha_*^{\mathcal{T}}}, {\boldsymbol \alpha_*^{\mathcal{G}}}$ . 输出的 $\boldsymbol c_t^d$ 是树和图的注意力加权向量的级联.
$$
\boldsymbol c_t^d =  \left[\sum_i \boldsymbol \alpha_{i,t}^{\mathcal{T}}\boldsymbol x_{i}^{\mathcal{T}}, \sum_i \boldsymbol \alpha_{i,t}^{\mathcal{G}}\boldsymbol x_{i}^{\mathcal{G}}\right]
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;..标签预测..&lt;/strong&gt;. 如果节点 $j_t$ 是 $i_t$ 生成的新节点, 其标签(表明它是何种分子骨架的标签)可以通过下式预测.
$$
\begin{aligned}
\boldsymbol c_t^l &amp;amp;=\text{attention}(\boldsymbol h_{i_t,j_t}, {\boldsymbol x_*^{\mathcal{T}}}, {\boldsymbol x_*^{\mathcal{G}}}; \boldsymbol U_{att}^l) \\&lt;br&gt;
\boldsymbol q_t &amp;amp;= \text{softmax}(\boldsymbol U^l\cdot\tau(\boldsymbol W_1^l\boldsymbol h_{i_t,j_t}+\boldsymbol W_2^l\boldsymbol c_t^l))
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;其中 $\boldsymbol q_t$ 是在标签集上的概率分布, $\boldsymbol U_{att}^l$ 是另一组计算注意力时的参数.&lt;/p&gt;
&lt;h3 id=&#34;图解码器&#34;&gt;图解码器&lt;/h3&gt;
&lt;p&gt;解码的第二步是从上一步预测的junction tree $\mathcal{\hat{T}}$ 出发, 构建分子图 $G$. 这个过程是非确定性的, 因为如下图所示, 同样的junction tree可以组装成不同的分子. 这一过程的自由度取决于原子团(树的节点)之间是如何连接的. 令 $\mathcal{G}_i$ 为一个分子图集合, 表示节点 $i$ 能发生的可能的连接方式对应的分子.&lt;/p&gt;
&lt;p&gt;每一个分子图 $G_i \in \mathcal G_i$ 都表示原子团 $C_i$ 和其邻居原子团 $\{C_j, j\in N_{\mathcal{\hat{T}}}(i)\}$ 的某种特定的连接方式. 这个图解码器的目标就是正确预测树中原子团的连接方式.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-06-02-114547.png&#34; title=&#34;相同的树可以组合为不同的分子.&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;为此, 本文作者设计了一个打分函数 $f(\cdot)$ 来对每一个 $\mathcal G_i$ 中的候选分子图 (对应连接方式) 进行排序. 首先, 用图消息传递网络对图 $G_i$ 计算原子表示 $\{\boldsymbol \mu_v^{G_i}\}$ . 然后使用sum-pooling求得图的表示 $\boldsymbol m_{G_i}=\sum_v \boldsymbol \mu_v^{G_i}$ . 最后, 通过点积函数为这个图打分 $f(G_i) = \sum_{u\in G}\boldsymbol m_{G_i}\cdot \boldsymbol x_u^{\mathcal{G}}$.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;解码器训练过程的损失函数是真值的子图和树中节点(原子团)的对数似然函数:
$$
\mathcal L_g(G) = \sum_i\left[ f(G_i)-\log\sum_{G_i&amp;rsquo;\in\mathcal G_i}exp(f(G_i&amp;rsquo;)) \right]
$$&lt;/p&gt;
&lt;h3 id=&#34;多模态图-图翻译&#34;&gt;多模态图-图翻译&lt;/h3&gt;
&lt;h4 id=&#34;变分junction-tree编码-解码器vjtnn&#34;&gt;变分Junction tree编码-解码器(VJTNN)&lt;/h4&gt;
&lt;p&gt;将上述模块组织起来形成整个模型&lt;/p&gt;
&lt;h4 id=&#34;分子骨架的对抗正则化&#34;&gt;分子骨架的对抗正则化&lt;/h4&gt;
&lt;p&gt;这部分旨在让模型输出正确的分子结构, 通过一个GAN来规范化模型,使得其输出正确的分子结构.&lt;/p&gt;
&lt;p&gt;(未完待续)&lt;/p&gt;
&lt;h2 id=&#34;个人感受&#34;&gt;个人感受&lt;/h2&gt;
&lt;p&gt;这篇文章的模型实在是太过复杂, 已经读了两三天了, 但是依然感觉有一些雾里看花. 一个很模糊的点是模型提出的动机, 例如: 如何解决文章开头提到的多模态图生成问题. 为什么要用编码器解码器这样的结构? 为什么要使用junction tree这样的有序树结构来表示无序的图? 为什么要联合树和图一起编码?&lt;/p&gt;
&lt;p&gt;个人认为其中缺乏很多解释, 更多的是搭建一个如何能完成这个任务的模型, 试想我们把化学分子换成蛋白质结构的空间距离图, 是不是也能用? 如果这样的话那究竟它编码的过程都&amp;quot;学&amp;quot;到了什么呢? 我认为作者应该更多解释一下如何从数据上刻画分子表示, 根据什么想法设计模型, 而非大量篇幅描述复杂的模型, 但模型某模块为什么加入. 这样我认为即使有好的结果也很难去解释为什么好. 虽然我看在Table2里,本文提出的结果似乎并没有比前人工作好多少, 甚至似乎都没有超出随机波动 (QED success提升2.5%, diversity提高0.045, novelty并没有提高. 第二个任务每一项指标都提高小于1个百分点). 另, 相比于VSeq2Seq模型直接翻译分子间的SMILES, 复杂性提升很多的模型却没有带来显著的性能提升, 是否应该有一些思考.&lt;/p&gt;
&lt;p&gt;另外, 我的前导师崔老师教导我, 写公式的时候不到万不得已千万不要用连续下表, 比如 $i_{j_k}$, 很容易让读者迷惑. 我真真切切感受到了. 这些复杂的表示其实换一种想法完全可以省略, 比如 $\boldsymbol \nu_{uv}^{(t)}$, 完全可以并入公式 (2) 中. 感觉文章写完, 希腊字母似乎都被用光了. 这也可能是化生学科和计算机学科之间在认知上的鸿沟吧!&lt;/p&gt;
&lt;p&gt;综上, 这篇文章咬牙看完, 看到最后结果汇总并和基线模型差距不大甚至无法超越的时候, 突然就丧失了一半继续写下去的动力, 然后转身去看代码, 发现代码是Python 2.7 + pytorch 0.4 + rdkit 2017.09! 不说别的, 这个环境配起来确实不是很方便, 至此, 丧失了另一半写下去的动力.&lt;/p&gt;
&lt;p&gt;如果以后有机会/需求的时候, 再接着这里写完吧!&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这里有问题. junction tree中的节点数目按理来说应该小于分子图, 因为树中一个节点代表一个子结构. 但这里公式却写着两个嵌入向量集合具有相同的向量个数, 可能有误! &lt;a href=&#34;https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这个打分函数我强烈怀疑有问题. 竟然解码的结果会和编码的结果比较, 这不就相当于解码器模型的输出好坏取决于输入吗? 个人感觉这里有问题. &lt;a href=&#34;https://minys233.github.io/posts/learning-multimodal-graph-to-graph-translation-for-molecular-optimization/#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" term="文献阅读" label="文献阅读" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/graph-auto-encoder-gae/" term="Graph Auto Encoder (GAE)" label="Graph Auto Encoder (GAE)" />
                            
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/machine-learning/" term="Machine Learning" label="Machine Learning" />
                            
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/%E6%9C%AA%E5%AE%8C%E6%88%90/" term="未完成" label="未完成" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">How Powerful Are Graph Neural Networks?</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/" />
            <id>https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/</id>
            <updated>2020-06-01T22:41:40&#43;08:00</updated>
            <published>2020-05-20T20:59:03&#43;08:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">读后总结, 刊于ICLR 2019</summary>
            
                <content type="html">&lt;h2 id=&#34;preliminary&#34;&gt;Preliminary&lt;/h2&gt;
&lt;h3 id=&#34;the-weisfeiler-lehman-isomorphism-test&#34;&gt;The Weisfeiler-Lehman Isomorphism Test&lt;/h3&gt;
&lt;p&gt;For a easy-to understand explanation, please refer to &lt;a href=&#34;https://davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/&#34;&gt;this link&lt;/a&gt;. Here, I simply summarize it briefly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-112619.png&#34; alt=&#34;Two isomorphic graphs&#34; title=&#34;Graph 1 and Graph 2 are isomorphic. The correspondance between nodes is illustrated by the node colors and numbers.&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In general, determining whether two graphs are isomorphic when the correspondance is not provided is a challenging problem; precisely how hard this problem is remains an open question in computer science. It isn&amp;rsquo;t known whether there is a polynomial time algorithm for determining whether graphs are isomorphic, and it also isn&amp;rsquo;t known whether the problem is NP-complete. The graph isomorphism problem may even be an example of an &lt;a href=&#34;https://en.wikipedia.org/wiki/NP-intermediate&#34;&gt;NP-intermediate&lt;/a&gt; problem, but this would only be possible if $P\ne NP$.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;From link above&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Weisfeiler-Lehman Isomorphism Test produces canonical forms of graphs. &lt;strong&gt;If the canonical forms of two graphs are not same, then two graphs are not isomorphic&lt;/strong&gt;. It is possible for two graphs to have same canonical forms but are not isomorphic. The algorithm iterative encode nodes (usually by a hash function) in a graph based on its neighbors to generate some kind of &amp;ldquo;fingerprint&amp;rdquo; or &amp;ldquo;signature&amp;rdquo;. With same initialization, we could find correspondance nodes in two graphs when they share the same fingerprint.&lt;/p&gt;
&lt;h3 id=&#34;graph-neural-network&#34;&gt;Graph neural network&lt;/h3&gt;
&lt;p&gt;最为常见的GNN范式可以如此描述.对于图 $G=(V,E)$ , $X_v$ 表示其节点 $v\in V$ 的特征向量(feature vector)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. 图网络的流程可以简单概括如下：
$$
\begin{aligned}
a_v^{(k)}&amp;amp;=\text{AGGREGATE}^{(k)}\left( \left\{\left. h_u^{(k-1)}\right|u\in \mathcal{N}(v) \right\} \right), \\&lt;br&gt;
h_v^{(k)} &amp;amp;= \text{COMGINE}^{(k)}\left( h_v^{(k-1)}, a_v^{(k)} \right),\\&lt;br&gt;
h_G &amp;amp;= \text{READOUT}\left( \left\{ \left. h_v^{(K)} \right| v\in G \right\} \right)
\end{aligned}
$$
其中, $h_v^{(k)}$ 表示节点 $v$ 在第 $k$ 层/循环时的特征向量; $h_v^{(k)}$ 的初始值为 $X_v$ ; $\mathcal{N}(v)$ 表示节点 $v$ 的邻居节点. 其中三个大写字母表示的函数是区别于不同GNN之间的重要因素. 大概汇总如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GraphSAGE (Hamilton et al., 2017a)
&lt;ul&gt;
&lt;li&gt;$a_v^{(k)}=\text{MAX}\left( \left\{\left. \text{ReLU}\left(W\cdot h_u^{(k-1)}\right)  \right|u\in \mathcal{N}(v) \right\} \right)$&lt;/li&gt;
&lt;li&gt;$h_v^{(k)} = W\cdot \left[ h_V^{(k-1)}, a_v^{(k)} \right]$&lt;/li&gt;
&lt;li&gt;$\text{MAX}$ 表示MaxPooling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GCN (Kipf &amp;amp; Welling, 2017)
&lt;ul&gt;
&lt;li&gt;$h_v^{(k)}=\text{ReLU}\left(W\cdot \text{MEAN}\left\{ h_u^{(k-1)}, \forall u\in \mathcal{N}(v)\cup {v}  \right\}\right)$&lt;/li&gt;
&lt;li&gt;两个函数合二为一&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常见的图上任务有两类：① 节点分类, 每个节点 $v$ 都有一个对应标签 $y_v$, GNN学到了节点表示 $h_v$ 后, 通过映射函数进行预测, 使得 $y_v=f(h_v)$ ; ②图分类, 对于每一个图 $G$, 都有一个标签 $y_G$ , 通过GNN学到图的表示 $h_G$ 后, 通过映射函数进行预测, 使得 $y_G=f(h_G)$.&lt;/p&gt;
&lt;h2 id=&#34;工作简述&#34;&gt;工作简述&lt;/h2&gt;
&lt;p&gt;文章通过理论论证+实验验证的方法指出了做出了两个主要贡献:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;论证并给出了各种GNN变体的表达能力的上限和达到的条件&lt;/li&gt;
&lt;li&gt;通过理论分析设计出了理论上更具优的网络结构GIN&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;理论证明&#34;&gt;理论证明&lt;/h2&gt;
&lt;p&gt;这里阐述一个大概的思路. 为了论证GNN的表示能力, 考察何种条件下GNN能将两个节点映射到嵌入空间中相同的位置. 理想情况下, 最具表达能力的GNN将两个节点映射到嵌入空间中相同的位置&lt;strong&gt;当且仅当&lt;/strong&gt;两个节点具有相同的子树结构 (aggregate N 次形成的树). 这表示GNN的 $\text{AGGREGATE}$ 函数必须是单射的. 而GNN这种区分能力的上限则是WL test. 作者证明,只有当$\text{AGGREGATE}$ , $\text{COMBINE}$ 以及 $\text{READOUT}$ 都是单射的时候, GNN将在描述节点的特征上达到WL test的性能.&lt;/p&gt;
&lt;p&gt;注: 文中这里提出了很多引理, 针对如何设计一个单射的multiset function. 这些是GIN设计及有效的证据.&lt;/p&gt;
&lt;h2 id=&#34;graph-isomorphism-network-gin&#34;&gt;Graph Isomorphism Network (GIN)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-155525.png&#34; alt=&#34;一些引理最终得到的命题&#34; title=&#34;由一些引理得到的命题&#34;&gt;&lt;/p&gt;
&lt;p&gt;这一命题构造了一系列符合要求的单设函数. 如果使用MLP学习其中的映射, 那么就得到了GIN的节点表示更新函数就可以写作为下式. 其中MLP可对前一次和下一次的 $\phi f$ 函数同时建模. 至此, 作者表明他们设计出了一个理论上达到表示能力上界的图神经网络.
$$
h_v^{(k)}=\text{MLP}^{(k)}\left(\left( 1+\epsilon^{(k)} \right)\cdot h_v^{(k-1)}+\sum_{u\in\mathcal{N}(v)}h_u^{(k-1)}\right)
$$
最后, 还差一个 $\text{READOUT}$ 函数. 作者提出, 在节点对应的遍历树逐渐趋近整个图的时候, 图中的特征将会有更好的判别性能. 但迭代轮数较小时候的特征却可以拥有更好的泛化性能&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. 因此作者表示为了能考虑到图中所有结构信息, 我们应当使用所有迭代过程中的特征. 作者通过一个与 Jumping Knowledge Network类似的架构实现了这样的操作:
$$
h_G=\text{CONCAT} \left( \text{READOUT}\left.\left.\left(\left\{h_v^{(k)}\right|v \in G\right\} \right) \right| k=0,1,\dots,K \right)
$$
根据上面的命题, 如果令 $\text{READOUT}$ 为求和函数, 那么它也将符合单射的条件. 作者在4个生信数据集+5个社交网络数据集上进行了测试, 结果自然是几乎全部怒砍第一.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-163130.png&#34; alt=&#34;GIN不同数据集上的测评结果&#34; title=&#34;GIN不同数据集上的测评结果&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;关于其他的gnn&#34;&gt;关于其他的GNN&lt;/h2&gt;
&lt;p&gt;其他的GNN虽然没有GIN这么强大,但是同样会捕捉一些图上有趣的性质. 作者针对GCN和GraphSAGE中不满足单设条件的①1层感知器, ②均值或max-pooling而非求和的 $\text{AGGREGATE}$ 函数做了消融实验. 它们都在一些图结构上无法分辨.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-164916.png&#34; alt=&#34;表达能力排序&#34; title=&#34;不同的 $\text{AGGREGATE}$ 函数的表示能力排序. Input表示将要输入的一堆目标节点的邻居; 右边排序说明了SUM捕捉到multiset中所有元素的特征; MEAN捕捉到了节点大致的分布; MAX忽视了multiset, 将其退化为简单地集合 (SET). 不同颜色的节点代表不同的特征值.&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;1层感知器&#34;&gt;1层感知器&lt;/h3&gt;
&lt;p&gt;文章证明了1层感知器 (线性组合+激活函数) 并不能对某些网络结构进行分辨. 即文中引理7:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lemma 7.&lt;/strong&gt; &lt;em&gt;There exist finite multisets&lt;/em&gt; $X_1 \ne X_2$ &lt;em&gt;so that for any linear mapping&lt;/em&gt; $W$, $\sum_{x\in X_1} \text{ReLU}(Wx)=\sum_{x\in X_2} \text{ReLU}(Wx)$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;证明过程主要思路是, 1层感知器和线性映射区别很小, GNN会退化到每一层仅仅将邻居节点求和. 另外, 众所周知, 1层感知器并不能对任意的函数进行近似.&lt;/p&gt;
&lt;h3 id=&#34;mean和max-pooling&#34;&gt;Mean和Max-pooling&lt;/h3&gt;
&lt;p&gt;这两个函数虽然都是组合不变的, 但是他们并非单射的. 根据之前的证明, 他们并不能区分某些图结构. 对于Mean函数,很容易能看出来, 它刻画的是周围邻居的均值, 或者可以理解为分布情况. 而对Max-pooling, 它则将原本是Multiset的邻居特征集合退化为一个简单集合, 并使用唯一元素代表所有邻居. 这些结论都有形式化证明, 这里不再赘述.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-21-165229.png&#34; alt=&#34;Mean和Max-pooling无法分辨的结构&#34; title=&#34;使得不同 $\text{AGGREGATE}$ 函数输出相同的图结构. 其中不同颜色代表不同的特征值. 简单计算就可以看出原因.&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;结果与总结&#34;&gt;结果与总结&lt;/h2&gt;
&lt;p&gt;这篇论文亮点就在通过WL test分析并设计的GNN确实在下游任务中比原来几种GNN好得多. 这篇文章代码也出奇简单. 有空一定要好好看看, 留个坑.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这里特征向量指的并非线性代数中的特征向量. &lt;a href=&#34;https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;作者没有解释, 我也不是很理解这里 &lt;a href=&#34;https://minys233.github.io/posts/how-powerful-are-graph-neural-networks/#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" term="文献阅读" label="文献阅读" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/graph-neural-network-gnn/" term="Graph Neural Network (GNN)" label="Graph Neural Network (GNN)" />
                            
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/machine-learning/" term="Machine Learning" label="Machine Learning" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">学术英语写作</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/%E5%AD%A6%E6%9C%AF%E8%8B%B1%E8%AF%AD%E5%86%99%E4%BD%9C/" />
            <id>https://minys233.github.io/posts/%E5%AD%A6%E6%9C%AF%E8%8B%B1%E8%AF%AD%E5%86%99%E4%BD%9C/</id>
            <updated>2020-06-01T22:22:19&#43;08:00</updated>
            <published>2020-05-20T15:30:54&#43;08:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">The process is seeded with $N$ vectors &amp;hellip; From Constrained Graph Variational Autoencoders for Molecule Design GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and trans- forming representation vectors of its neighboring…
    
    </summary>
            
                <content type="html">&lt;blockquote&gt;
&lt;p&gt;The process is &lt;strong&gt;seeded with&lt;/strong&gt; $N$ vectors &amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;Constrained Graph Variational Autoencoders for Molecule Design&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GNNs &lt;strong&gt;follow&lt;/strong&gt; a neighborhood aggregation &lt;strong&gt;scheme&lt;/strong&gt;, where the representation vector of a node is computed by recursively aggregating and trans- forming representation vectors of its neighboring nodes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Recently, there has been &lt;strong&gt;a surge of interest in&lt;/strong&gt; Graph Neural Network (GNN) approaches for representation learning of graphs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;How Powerful Are Graph Neural Networks?&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Since molecules can be optimized in different ways, there are multiple viable translations for each input graph.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;Learning Multimodal Graph to Graph Translation for Molecular Optimization&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; converge to &lt;strong&gt;brittle&lt;/strong&gt; solutions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;&lt;a href=&#34;https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html&#34;&gt;Ankesh Anand&amp;rsquo;s blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of drug discovery is to design molecules with desirable chemical properties. The task is challenging since the chemical space is vast and often difficult to navigate.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;em&gt;Learning Multimodal Graph to Graph Translation for Molecular Optimization&lt;/em&gt;&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" term="文献阅读" label="文献阅读" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/academic-writing/" term="Academic Writing" label="Academic Writing" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">Strategies for Pre Training Graph Neural Networks</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/" />
            <id>https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/</id>
            <updated>2020-05-22T12:54:09&#43;08:00</updated>
            <published>2020-05-20T15:26:23&#43;08:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">读后总结，刊于ICLR 2020</summary>
            
                <content type="html">&lt;h2 id=&#34;问题提出&#34;&gt;问题提出&lt;/h2&gt;
&lt;p&gt;文章首先提出迁移学习在CV与NLP中已经应用广泛了，但在图数据上相应的预训练的工作还比较少。预训练主要解决目前图数据集的两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;task-specific labeled data can be extremely scarce.&lt;/li&gt;
&lt;li&gt;Graph data from real-world often contain out-of-distribution samples.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第一个问题很好理解，在化学生物领域中，图数据（eg: molecule, protein, etc.）对应的标签的获取过程需要做实验，是资源密集且时间密集的。第二个问题个人理解指的是数据的整体分布和条件分布的区别。例如，所有已发现的分子数据库可看作是整体分布。而对特定的任务如MoleculeNet中的BBBP数据集&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，数据的分子则是在某些隐含条件下的，如具有一定的水溶性和脂溶性、常温下不太可能是气体、不太可能含有特定有毒的重金属元素/官能团。&lt;/p&gt;
&lt;p&gt;因此，不少研究都发现，简单地增加有标数据的量并不能一定让预训练或迁移学习进行得更好。相反，预训练需要领域知识来合理地选择和特定下游任务有关的数据。相反，如果下游任务和预训练的任务差别太大，则有可能导致“负迁移”（negative transfer）的问题。&lt;/p&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;h3 id=&#34;简述&#34;&gt;简述&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-170447%402x.png&#34; alt=&#34;思路简述&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图，本文提出使用节点水平+图水平的预训练使得图网络既能学到节点与边层面上的特征（局部特征），也能捕捉到图级别的特征（全局特征）。作者为预训练设计了特定的任务，如上图右边，以此来对特定的图中信息进行建模。本文通过对比使用了比较新GIN模型作为预训练的图网络。&lt;/p&gt;
&lt;h3 id=&#34;节点的预训练&#34;&gt;节点的预训练&lt;/h3&gt;
&lt;p&gt;承上，节点的预训练作者提出了两种方案，分别针对邻居结构信息和自身节点信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-170517%402x.png&#34; alt=&#34;节点嵌入&#34;&gt;&lt;/p&gt;
&lt;p&gt;**Context prediction.**对每一个节点 $v$ ， $K$-hop 邻居指该节点出发最多 $K$-hop 以内的所有节点和边。也即是一个常见的 $K$ 层GNN能够搜集信息的范围，对应节点的表示向量 $h_v^{(K)}$ 则取决于它的 $K$-hop 邻居。Context graph 表示一些节点 $v$ 的邻居结构。它由两个参数 $r_1, r_2$ 控制。对于节点 $v$，表示由所有与 $v$ 距离 $r_1$-hop 和 $r_2$-hop 之间的节点和边所构成的子图，可近似看做一个环形区域。令 $r_1 &amp;lt; K$，并将 $K$-hop 邻居和Context graph的交集被称为Context anchor nodes。这一任务如上图(a)所示，第一步先使用一个辅助GNN&amp;rsquo;来得到Context graph中的节点向量表示，并对Context anchor nodes的表示求平均，得到绿色的向量，对于图 $G$ 中的节点 $v$ ，这样得到的向量为 $c_v^G$。第二步，用主GNN在 $K$-hop 邻居组成的子图上得到 $v$ 的表示 $h_v^{(K)}$。预训练的目标即为：
$$
\sigma(h_v^{(K)}\cdot c_{v&amp;rsquo;}^G) \approx 1 \;\;\text{if $v$ and $v&#39;$ are same node}
$$
$\sigma(\cdot)$ 表示$\text{Sigmoid}$函数。第三部，在训练中使用negative sampling，控制 $v&#39;=v$ 或 $G&#39;=G$，让正负样本比例为1。这实际上是要学到图的拓扑结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Attribute masking.&lt;/strong&gt; 随机mask掉分子图中的一些节点和边的属性，使用GNN预测。这个任务原理没有这么复杂，不再赘述。&lt;/p&gt;
&lt;h3 id=&#34;图的预训练&#34;&gt;图的预训练&lt;/h3&gt;
&lt;p&gt;图 $G$ 的向量表示 $h_G$ 下游任务进行微调训练时候直接使用的特征，我们应当让这类特征包含相关的领域知识。作者提出，使用图级别多任务有监督预训练（graph-level multi-task supervised pre-training）来同时预测同一个图的多个标签。但是，如果只是单纯的这样训练，如果预训练的任务与下游任务相关性不强或，则可能出现负迁移的现象。因此，作者认为图的预训练仅仅提供了图层面上的监督，即使节点表示学的很好，但图表示很可能在预训练阶段由于各种原因是没那么有意义的。因此，作者表示要缓解这个问题，就要先进行节点预训练，再进行图的预训练&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;。另外，作者还说可以用图网络预测图之间的相似性来进行图的预训练。然而他说这个复杂度太高，他不做。&lt;/p&gt;
&lt;h2 id=&#34;实验和结果&#34;&gt;实验和结果&lt;/h2&gt;
&lt;p&gt;实验分别在化学任务和生物学任务上进行预训练效果测试。预训练数据来源是ZINC15，只在其中选了2百万个分子&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;。详细数据和方法略去，仅介绍结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-183500%402x.png&#34; alt=&#34;所有下游任务和与训练策略的比较&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是GIN使用不同的与训练策略在下游任务（化学）中的表现，测评指标是ROC-AUC（%）。加粗字体表示最好的几个（best and comparable），灰框的表示出现了负迁移，结果比不预训练的网络还差。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-183515%402x.png&#34; alt=&#34;不同模型是否预训练的结果变化&#34;&gt;&lt;/p&gt;
&lt;p&gt;不同图网络模型在化学和生物两大类下游任务中的表现，比较预训练与否所带来的ROC-AUC（%）的变化，可以轻松看出GIN是最适合预训练的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-184420%402x.png&#34; alt=&#34;使用GIN与不同与训练策略进行蛋白质功能预测&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://minys-blog.oss-cn-beijing.aliyuncs.com/2020-05-20-WX20200520-184432%402x.png&#34; alt=&#34;不同与训练策略的训练集和验证集ROC-AUC变化情况&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;印证了越复杂的模型就越能更好地利用预训练，相反，越有限的模型就越不能受益于预训练。&lt;/li&gt;
&lt;li&gt;仅仅进行了图级别的预训练是不够的，将导致较多负迁移现象（2/8）。&lt;/li&gt;
&lt;li&gt;仅仅进行了节点级别的预训练也是不够的，也会导致负迁移现象（1/8）。&lt;/li&gt;
&lt;li&gt;结合节点级别和图级别的预训练将能达到最优的下游任务表现，同时消除了负迁移。&lt;/li&gt;
&lt;li&gt;作者声称他的方法做到了目前最好&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;
&lt;li&gt;与训练模型在下游任务训练时能更快收敛（显然）。&lt;/li&gt;
&lt;/ol&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这个数据集是测量一些化合物是否能突破人体血脑屏障的。 &lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这不是废话吗😓，反过来的话节点的预训练不就没用了。感觉这里把问题没讲清楚，实际上文中似乎就是把能获取到的数据都拿来预训练。 &lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;我个人也发现无标签分子的预训练一两百万就差不多很足够了，再多就没有意义了。 &lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;存疑，这几个数据集合同样是scaffold划分，都没有达到MoleculeNet的给出的结果，不知是如何state-of-the-art的。 &lt;a href=&#34;https://minys233.github.io/posts/strategies-for-pre-training-graph-neural-networks/#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" term="文献阅读" label="文献阅读" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/graph-neural-network-gnn/" term="Graph Neural Network (GNN)" label="Graph Neural Network (GNN)" />
                            
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/machine-learning/" term="Machine Learning" label="Machine Learning" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">功能测试</title>
            <link rel="alternate" type="text/html" href="https://minys233.github.io/posts/test-my-site/" />
            <id>https://minys233.github.io/posts/test-my-site/</id>
            <updated>2020-06-22T20:22:55&#43;08:00</updated>
            <published>2020-05-19T18:49:55&#43;00:00</published>
            <author>
                    <name>Minys</name>
                    <uri>blog.minys.online</uri>
                    <email>minys@foxmail.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</rights><summary type="html">这是一个一级标题 这是一个二级标题 数学公式 简单公式$A+B=C$这是行内公式 $$ a^2 + b^2 =…
    
    </summary>
            
                <content type="html">&lt;h1 id=&#34;这是一个一级标题&#34;&gt;这是一个一级标题&lt;/h1&gt;
&lt;h2 id=&#34;这是一个二级标题&#34;&gt;这是一个二级标题&lt;/h2&gt;
&lt;h1 id=&#34;数学公式&#34;&gt;数学公式&lt;/h1&gt;
&lt;p&gt;简单公式$A+B=C$这是行内公式
$$ a^2 + b^2 = c^2$$&lt;/p&gt;
&lt;p&gt;$$x=\frac{-b\pm\sqrt{4ac}}{2a}$$
复杂公式
$$
\begin{aligned}
\mathcal{L} ( \mu ,\sigma^2 ) &amp;amp;= \prod_{i = 1}^n \left\lbrace  \frac{1}{\sqrt{2 \pi} \sigma } \text{exp} \left\lbrace - \frac{( x_i - \mu)^2}{2 \sigma^2}\right\rbrace \right\rbrace ,\\&lt;br&gt;
&amp;amp;= (2 \pi \sigma^2)^{- \frac{n}{2}} \text{exp} \left\lbrace - \frac{1}{2 \sigma^2} \sum_{i = 1}^{n} (x_i - \mu)^2 \right\rbrace .
\end{aligned}
$$&lt;/p&gt;
&lt;h1 id=&#34;公式作为toc项目&#34;&gt;公式作为TOC项目&lt;/h1&gt;
&lt;h2 id=&#34;xfrac-bpmsqrt4ac2a&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h2&gt;
&lt;h3 id=&#34;xfrac-bpmsqrt4ac2a-1&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h3&gt;
&lt;h4 id=&#34;xfrac-bpmsqrt4ac2a-2&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h4&gt;
&lt;h5 id=&#34;xfrac-bpmsqrt4ac2a-3&#34;&gt;$x=\frac{-b\pm\sqrt{4ac}}{2a}$&lt;/h5&gt;
&lt;p&gt;一元二次方程解的公式$x= \frac{-b\pm\sqrt{4ac}}{2a}$&lt;/p&gt;
&lt;h1 id=&#34;化学式ceh3o&#34;&gt;化学式$\ce{H3O+}$&lt;/h1&gt;
&lt;p&gt;$\ce{[AgCl2]-}$&lt;/p&gt;
&lt;p&gt;$\ce{NaOH(aq,$\infty$)}$&lt;/p&gt;
&lt;p&gt;$\ce{Hg^2+ -&amp;gt;[I-]  $\underset{\mathrm{red}}{\ce{HgI2}}$  -&amp;gt;[I-]  $\underset{\mathrm{red}}{\ce{[Hg^{II}I4]^2-}}$}$&lt;/p&gt;
&lt;h1 id=&#34;emoji&#34;&gt;Emoji&lt;/h1&gt;
&lt;p&gt;🌶💉🔟🐮🍺&lt;/p&gt;
&lt;h1 id=&#34;代码块&#34;&gt;代码块&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bar&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
      &lt;span class=&#34;k&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;this is {self.foo}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;mermaid&#34;&gt;Mermaid&lt;/h2&gt;

&lt;div class=&#34;mermaid&#34; align=&#34;center&#34;&gt; 
    
graph LR;
	A[Hard edge] --&gt;|Link text| B(Round edge)
    B --&gt; C{Decision}
    C --&gt;|One| D[Result one]
    C --&gt;|Two| E[Result two]

&lt;/div&gt;&lt;span class=&#34;caption&#34;&gt;👉 This is a flowchart&lt;/span&gt;
&lt;p&gt;通过shortcode的设置, 当允许图表图例时, 可以通过接收caption参数为mermaid图表加上图例. 但注意要在前后加上空行, 不然这一段就和图表处在同一段了!&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/categories/%E9%9A%8F%E4%BE%BF%E5%86%99%E5%86%99/" term="随便写写" label="随便写写" />
                            
                        
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://minys233.github.io/tags/%E6%B5%8B%E8%AF%95/" term="测试" label="测试" />
                            
                        
                    
                
            
        </entry>
    
</feed>
